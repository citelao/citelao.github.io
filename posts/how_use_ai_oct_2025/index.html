<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZN0HVXBFN4"></script><script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
		
		gtag('config', 'G-ZN0HVXBFN4');
	</script><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Blog RSS Feed"><link rel="sitemap" href="/sitemap-index.xml"><link rel="icon" href="/favicon.ico" sizes="32x32"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="generator" content="Astro v5.5.5"><title>How I use AI (Oct 2025) - Ben Stolovitz</title><meta name="description" content="AI has transformed how I code and do research. Hereâ€™s where itâ€™s good and where it is lacking."><link rel="canonical" href="https://ben.stolovitz.com/posts/how_use_ai_oct_2025/"><meta property="og:url" content="https://ben.stolovitz.com/posts/how_use_ai_oct_2025/"><meta property="og:type" content="article"><meta property="og:title" content="How I use AI (Oct 2025)"><meta property="og:description" content="AI has transformed how I code and do research. Hereâ€™s where itâ€™s good and where it is lacking."><meta property="og:sitename" content="ben.stolovitz.com"><meta property="og:image" content="/_astro/og.B__LH-Yx_Z2orTKl.png"><meta property="og:image:alt" content="A person wonders at a group of eager robots"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="article:published_time" content="2025-10-31T00:00:00.000Z"><meta property="article:modified_time" content="2025-11-01T20:51:55.000Z"><meta property="article:author" content="Ben Stolovitz"><meta name="twitter:card" content="summary_large_image"><meta property="twitter:domain" content="ben.stolovitz.com"><meta property="twitter:url" content="https://ben.stolovitz.com/posts/how_use_ai_oct_2025/"><meta name="twitter:title" content="How I use AI (Oct 2025)"><meta name="twitter:description" content="AI has transformed how I code and do research. Hereâ€™s where itâ€™s good and where it is lacking."><meta name="twitter:image" content="/_astro/og.B__LH-Yx_Z2orTKl.png"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Figtree:ital,wght@0,300..900;1,300..900&family=Inknut+Antiqua:wght@700&display=swap" rel="stylesheet"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack-subset.css"><link rel="stylesheet" href="/_astro/_path_.m8Wn46M7.css">
<style>section[data-astro-cid-3jjkyeai]{background-color:var(--aside-background);border-radius:var(--big-corner);padding:1rem;max-width:30rem}h2[data-astro-cid-3jjkyeai]{margin-top:0;margin-bottom:0}small[data-astro-cid-3jjkyeai]{display:block;margin-top:.5rem;margin-bottom:0}form[data-astro-cid-3jjkyeai]{display:flex;flex-direction:row;gap:.5rem;margin-top:.5rem}input[data-astro-cid-3jjkyeai]:not([type=submit]){appearance:none;font-size:inherit;font-family:inherit;flex-grow:1;background-color:var(--background);border:1px solid var(--background);border-radius:var(--small-corner);padding:.2em .4em;color:inherit}input[data-astro-cid-3jjkyeai]:not([type=submit]):hover{border-color:var(--foreground)}.subscribe[data-astro-cid-3jjkyeai],button[data-astro-cid-3jjkyeai],input[data-astro-cid-3jjkyeai][type=submit]{display:inline-block;appearance:none;font-size:inherit;font-family:inherit;text-decoration:none;cursor:pointer;color:var(--link-contrast);padding:.5rem;border-radius:var(--small-corner);border:1px solid transparent}.subscribe[data-astro-cid-3jjkyeai]:hover,.subscribe[data-astro-cid-3jjkyeai]:focus,button[data-astro-cid-3jjkyeai]:hover,button[data-astro-cid-3jjkyeai]:focus,input[data-astro-cid-3jjkyeai][type=submit]:hover,input[data-astro-cid-3jjkyeai][type=submit]:focus{background-color:var(--background);color:var(--link-contrast);border:1px solid var(--link-contrast);transform:none}.subscribe[data-astro-cid-3jjkyeai]:hover,button[data-astro-cid-3jjkyeai]:hover,input[data-astro-cid-3jjkyeai][type=submit]:hover{transform:translateY(-1px)}.subscribe[data-astro-cid-3jjkyeai]:active,button[data-astro-cid-3jjkyeai]:active,input[data-astro-cid-3jjkyeai][type=submit]:active{transform:translateY(1px)}
@charset "UTF-8";.article aside{background-color:var(--aside-background);padding:.5rem 1rem;margin-left:2rem;margin-right:2rem;font-size:.9rem;border-radius:var(--big-corner)}@media print{.article aside{border:1px solid var(--chart-tick-foreground);background-color:transparent}}.article aside p:first-child,.article aside h1:first-child,.article aside h2:first-child,.article aside h3:first-child,.article aside h4:first-child,.article aside h5:first-child{margin-top:0}.article aside>p:last-child{margin-bottom:0}.article .appendix{background-color:var(--aside-background);padding:.5rem 1rem;font-size:.9rem;border-radius:var(--big-corner)}@media print{.article .appendix{border:1px solid var(--chart-tick-foreground);background-color:transparent}}.article .appendix+.appendix{margin-top:1rem}.article .appendix h1,.article .appendix h2,.article .appendix h3,.article .appendix h4,.article .appendix h5{margin-top:.5rem}.article blockquote{margin:0;margin-left:1.5rem}.article blockquote .source{display:block;text-align:right;margin-right:1rem;font-size:.8rem;clear:both;color:var(--code-foreground)}.article blockquote .source:before{content:"â€” "}.article .equation{display:flex;align-items:center;gap:.2rem}.article figure{margin:0 auto;text-align:center;font-size:.8rem}.article figure.image_figure{max-width:80%}@media print{.article figure.image_figure{max-width:50%}}.article figure p{margin:0}.article figure figcaption{color:var(--code-foreground)}.article figure img{border-radius:var(--big-corner)}.article li>p+.image_figure{margin-top:1rem}.article .deemphasized{color:var(--code-foreground)}.article table td,.article table th{padding:.2rem}.article table tr:nth-child(2n){background:var(--table-alternate-background)}.article .key_image{margin:0 auto;max-width:100%}.article img{max-width:90%;height:auto}.email{margin:2rem auto}body{display:flex;gap:2rem;flex-wrap:wrap;align-items:flex-start}main[data-astro-cid-egg7nqdx]{max-width:40rem;width:100%;text-wrap:pretty}@media print{main[data-astro-cid-egg7nqdx]{max-width:8in}}aside[data-astro-cid-egg7nqdx]{font-size:.8rem;text-align:center}.bottom_nav[data-astro-cid-egg7nqdx]{display:flex;margin-bottom:1rem;justify-content:space-between;gap:1rem}.bottom_nav[data-astro-cid-egg7nqdx] .prev[data-astro-cid-egg7nqdx]{grid-column:prev/span 1}.bottom_nav[data-astro-cid-egg7nqdx] .next[data-astro-cid-egg7nqdx]{grid-column:next/span 1}@media print{.bottom_nav[data-astro-cid-egg7nqdx]{display:none}}h1[data-astro-cid-egg7nqdx]{font-size:1.4rem}nav[data-astro-cid-egg7nqdx]{margin-top:1.5rem}@media print{nav[data-astro-cid-egg7nqdx]{display:none}}
._volumeSimulator_2iv9s_1{text-align:center;background-color:var(--aside-background);padding:1rem;border-radius:var(--big-corner);position:relative;display:flex;gap:1rem;flex-direction:column}@media print{._volumeSimulator_2iv9s_1{border:1px solid var(--chart-tick-foreground);background-color:transparent}}._volumeStatus_2iv9s_18{display:grid;grid-template-columns:1fr [output] max-content [sound] 1fr}._playing_2iv9s_23{grid-column:sound;text-align:right}._volumeOutput_2iv9s_28{background:var(--gruv-bg);color:var(--gruv-fg);border-radius:var(--small-corner);padding:.2rem .5rem;margin:0;grid-column:output;text-align:left;min-width:12rem}._volumeOutput_2iv9s_28 span{overflow:hidden}@media print{._volumeOutput_2iv9s_28{background:transparent;color:var(--foreground)}}._placeholder_2iv9s_48{opacity:.5}._volumeButton_2iv9s_52._volumeButton_2iv9s_52{padding:2rem;border-radius:var(--small-corner);background-color:var(--table-alternate-background);font-size:2rem;line-height:.5;border:.1rem solid var(--kbd-border);border-bottom-width:.4rem;cursor:pointer}@media print{._volumeButton_2iv9s_52._volumeButton_2iv9s_52{background:transparent;color:var(--foreground)}}._volumeButton_2iv9s_52._volumeButton_2iv9s_52:hover,._volumeButton_2iv9s_52._volumeButton_2iv9s_52:focus{margin-top:.3rem;border-bottom-width:.1rem}._volumeButton_2iv9s_52._volumeButton_2iv9s_52:active{background-color:var(--link)}._buttonGroup_2iv9s_76{display:flex;justify-content:center;gap:.2rem}._volumeOptions_2iv9s_82{display:flex;flex-direction:column;justify-content:center;align-items:center}
@keyframes _slideInFromLeft_1hpfe_1{0%{opacity:0}to{opacity:1}}._themeButton_1hpfe_9{appearance:none;padding:.5rem;border-radius:1rem;background:var(--table-alternate-background);border:0;cursor:pointer;position:fixed;top:1.3rem;right:1rem;animation:.3s ease-out 0s 1 _slideInFromLeft_1hpfe_1}._themeButton_1hpfe_9:hover,._themeButton_1hpfe_9:focus{background:var(--link);color:var(--background)}@media print{._themeButton_1hpfe_9{display:none}}
</style></head> <body> <script>
		(function() {
			// Duplicate of theme.ts
			//
			// Why? To immediately set the theme on page load.
			// See https://www.joshwcomeau.com/react/dark-mode/.
			// Adaptation: we also disable the transition on load.
			function getCurrentTheme() {
				if (typeof localStorage !== "undefined" && localStorage.getItem("theme")) {
					return localStorage.getItem("theme");
				}
	
				if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
					return "dark";
				}
				return "light";
			}

			// Add no-transition class to prevent transitions on load
			console.log("Activating theme...");
			document.documentElement.classList.add("no-transition");
			const theme = getCurrentTheme();
			const element = document.documentElement;
			element.classList.toggle("dark", theme === "dark");

			// Request animation frame to ensure this runs after any other initial JS
			requestAnimationFrame(() => {
				document.documentElement.classList.remove("no-transition");
			});
		})();
	</script>     <nav data-astro-cid-egg7nqdx> <a href="/" data-astro-cid-egg7nqdx>&larr; back home</a> </nav> <main data-astro-cid-egg7nqdx>  <article class="article" data-astro-cid-egg7nqdx> <h1 data-astro-cid-egg7nqdx>How I use AI (Oct 2025)</h1> <p>I want to take stock of how Iâ€™m currently using AIâ€Šâ€”â€Šat least, the cool stuff like LLMs that we <em>call</em> â€œAI.â€ Iâ€™m curious to see this evolve in the coming years.</p>

<picture> <source srcset="/_astro/cover-dark.CwT1zN4s_294Hi2.webp 500w, /_astro/cover-dark.CwT1zN4s_Z2fz74i.webp 1000w, /_astro/cover-dark.CwT1zN4s_Z257Vjr.webp 1500w" type="image/webp">  <img src="/_astro/cover-dark.CwT1zN4s_dqtF0.png" srcset="/_astro/cover-dark.CwT1zN4s_dqtF0.png 500w, /_astro/cover-dark.CwT1zN4s_Z117iz6.png 1000w, /_astro/cover-dark.CwT1zN4s_dqtF0.png 1500w" alt="A person wonders at a group of eager robots" width="500" height="350" loading="lazy" decoding="async" class="key_image light-hidden"> </picture> <picture> <source srcset="/_astro/cover.BUA-tVJ__Z1esOHr.webp 500w, /_astro/cover.BUA-tVJ__xd2L7.webp 1000w, /_astro/cover.BUA-tVJ__Ddlcv.webp 1500w" type="image/webp">  <img src="/_astro/cover.BUA-tVJ__Z2oAxeN.png" srcset="/_astro/cover.BUA-tVJ__Z2oAxeN.png 500w, /_astro/cover.BUA-tVJ__Zj3Vw.png 1000w, /_astro/cover.BUA-tVJ__Z2oAxeN.png 1500w" alt="A person wonders at a group of eager robots" width="500" height="350" loading="lazy" decoding="async" class="key_image dark-hidden"> </picture>
<h2 id="background">Background</h2>
<p>I believe I use AI fairly typically for a software engineer, if slightly more than average. Iâ€™ve been working in the AI space since slightly before the announcement of GPT-3 in 2020.</p>
<p>I use AI in a few particular ways:</p>
<ul>
<li>Coding</li>
<li>Research &amp; search</li>
<li>Summarization &amp; transcription</li>
<li>Writing</li>
<li>Art &amp; music</li>
</ul>
<p>This is, of course, purely my opinion &amp; speculation. If you have different ways of using AI, Iâ€™d love to know!</p>
<h2 id="coding">Coding</h2>
<p>Coding is the part of my life most changed with AI, by far.</p>
<p>I started using Copilot very early: Microsoft quickly deployed access to Github Copilot internally, so Iâ€™ve used that since nearly Day 1. Iâ€™m a <strong>huge</strong> fan. Its suggestions are incredible and save me (hundreds of?) keystrokes every day. I expect other tools, like Claude Code, are just as good.</p>
<figure class="image_figure"><p><img src="/_astro/autocomplete.DIDqaQT6_Z1KHl8P.webp" alt="Code with a line of about 50 chars italicized" width="1422" height="598" loading="lazy" decoding="async">
<figcaption>Copilot autocomplete correctly predicting an entire line of code (the italic line)</figcaption></p></figure>
<p>I mainly use <strong>autocomplete</strong>:</p>
<ul>
<li>
<p>It completes stuff <em>I already know how to do</em>. Itâ€™s very good at predicting my next line, so I simply tab-complete much of my code. Google reported in 2024 that <a href="https://research.google/blog/ai-in-software-engineering-at-google-progress-and-the-path-ahead/#:~:text=assisting%20in%20the%20completion%20of%2050%25%20of%20code%20characters">50% of code characters written internally</a> were from AI tab completionâ€Šâ€”â€Šit simply <em>is</em> that good.</p>
</li>
<li>
<p>It helps me <em>discover idiomatic patterns &amp; syntax</em>. It reliably predicts how to deserialize JSON in C#, which Iâ€™d otherwise need to look up.</p>
</li>
<li>
<p>(Itâ€™s mediocre at <em>writing complicated algorithms</em>. It tends to spew pages of incorrect code. Iâ€™m still finding the balance, but it often takes me longer to validate its code than to write it myself).</p>
</li>
</ul>
<p>Altogether, itâ€™s good enough that Iâ€™ll frequently <em>wait for a suggestion to appear</em>, even if it takes thirty seconds. In these respects, itâ€™s a beefed-up <a href="https://code.visualstudio.com/docs/editing/intellisense">IntelliSense</a>, and itâ€™s magical. 10 out of 10.</p>
<p>Iâ€™ve also started using <strong>agent mode</strong>, where it plans &amp; writes complicated changes on its own. Itâ€™s been less â€œmagically goodâ€ and less mind-blowingly useful. But its quality often surprises me.</p>
<p>I like to tag these AI commits with <code>(AI)</code> so I can find them later: hereâ€™s <a href="https://github.com/citelao/systray-doom/commit/ccb889ff2ff1ec4a00f92f5f7d581564ddad5581">a commit improving logging</a> in a project, and a subsequent <a href="https://github.com/citelao/systray-doom/commit/aa1c3c7bf5191eab887a0a12c5eb333d944e2ee7">commit making the output prettier</a>. These commits took about ~10min to generate; writing the code manually would have taken much longer since Iâ€™m unfamiliar with logging in .NET. Iâ€™ve tried before, but documentation was so dense that I failed multiple times. Agents are helping me understand idioms that ASP.NET developers understand implicitly.</p>
<aside class="sidenote"><h3 id="agent-mode-needs-tests--guidance">Agent mode needs tests &amp; guidance</h3><p>I find that 2 things are vital for agent mode to work properly:</p><ul>
<li><strong>Testing testing testing</strong>. Agents must be able to verify their work with unit tests or functional tests or whatnot. They are abysmal when they cannot verify things (you should see some UI &amp; accessibility fixes Iâ€™ve asked them to do).</li>
<li><strong>AGENTS.md</strong>. Agents need guidance, even to say &quot;read <code>CONTRIBUTING.md</code>â€œ or &quot;donâ€™t add comments to every line.â€ Simple guidance makes these agents a lot less tedious to review. (I like to ask agents to <a href="https://github.com/citelao/systray-doom/commit/1067a5949855920757e132b57809ead53003a41e#diff-a54ff182c7e8acf56acfd6e4b9c3ff41e2c41a31c9b211b2deb9df75d9a478f9">include 1 emoji in their output</a> to prove theyâ€™ve read the guidance).</li>
</ul></aside>
<p>Despite that, I still need to babysit agents. They tend to get lost when doing unconventional things, like using opaquely-documented Win32 APIs or calling PowerShell from C#. The logging commits exemplify what agents excel at: implementing a common idiom that has lots of training data, so AI knows it well.</p>
<p>This is why Iâ€™m still tepid on <strong>agentic pull requests</strong>. In my experience, agents still need a human in the loop to validate changes &amp; unblock errors. PRs lengthen that loop, which slows you down (you now must check out a branch &amp; build it to validate any changes). I was able to use Codex to <a href="https://github.com/citelao/systray-doom/pull/4">add GitHub actions</a> to a project of mine, but I gave up on <a href="https://github.com/citelao/systray-doom/pull/6/files">a subsequent PR</a> auto-incrementing versions in favor of <a href="https://github.com/citelao/systray-doom/pull/7">a manual PR</a> I wrote with agents locally. The agentic PR simply had too many errors to be worth fixing.</p>
<p>AI <strong>code review</strong> is a bit better. Iâ€™ve worked with agents that leave tedious, harmful comments (like â€œconsider catching exceptionsâ€ in code where doing so would mask larger problems). But Codex caught a <em>severe</em> potential use-after-free bug <a href="https://github.com/citelao/systray-doom/pull/8#discussion_r2461845675">in some of my hand-written code</a>. Thatâ€™s pretty cool.</p>
<figure class="image_figure"><p><img src="/_astro/code-review.BoGuvG2z_Zddpfs.webp" alt="Codex review comment: 'Built menu items hold unpinned string pointers'" width="1660" height="1362" loading="lazy" decoding="async">
<figcaption>AI code review points out a potentially big issue</figcaption></p></figure>
<p>I only rarely use <strong>inline editing</strong> (I usually use autocomplete instead), and agent mode has fully replaced the old one-shot <strong>code mode</strong> in GitHub Copilot (code mode rarely had enough context to be useful).</p>
<p>In short:</p>








































<table><thead><tr><th style="text-align:right"></th><th style="text-align:center">Usefulness</th><th>Notes</th></tr></thead><tbody><tr><td style="text-align:right"><strong>Autocomplete</strong></td><td style="text-align:center">ğŸ‘ğŸ‘ğŸ‘</td><td>Industry-changing!</td></tr><tr><td style="text-align:right"><strong>Agent mode</strong></td><td style="text-align:center">ğŸ‘</td><td>Increasingly useful. Needs documentation &amp; testability to be successful</td></tr><tr><td style="text-align:right"><strong>Agentic PRs</strong></td><td style="text-align:center">ğŸ¤”</td><td>Validation loop too slow to be productive</td></tr><tr><td style="text-align:right"><strong>Code review</strong></td><td style="text-align:center">ğŸ¤”</td><td>Need to sort out signal from noise</td></tr><tr><td style="text-align:right"><strong>Inline editing</strong></td><td style="text-align:center">âŒ</td><td>Slower to use than autocomplete</td></tr><tr><td style="text-align:right"><strong>Code mode</strong></td><td style="text-align:center">âŒ</td><td>Usurped by agent mode</td></tr></tbody></table>
<h2 id="research--search">Research &amp; search</h2>
<p>Research &amp; search are a close second in &quot;life changiness&quot;: theyâ€™re the most frequent reason I use ChatGPT.</p>
<p>I find LLMs mediocre at <strong>traditional search</strong>. Theyâ€™re not search engines: when I ask ChatGPT (or Claude) to find good Italian food, it reliably hallucinates restaurants that closed in 2023. When I ask the LLMs to â€œcite your sources,â€ they perform much better (which makes sense: they are trained on old data, so asking them to search the web helps). Even with citations, though, LLMs have been terrible at <strong>product searches</strong> like <a href="https://chatgpt.com/share/68f03caf-9194-8013-ac56-611a79c50e5f">finding a new USB hub</a>. I suspect thatâ€™s because searching for products <em>without</em> AI is also similarly frustrating: results are filled with advertisements and SEO spam, most large reviewers recommend the same few products, and Redditors flock to faddy, niche, expensive stuff (<a href="https://www.youtube.com/watch?v=4ZK8Z8hulFg">relevant ProZD</a>). Iâ€™m not surprised LLMs offer vague and uninspired advice.</p>
<p>Instead I use LLMs for <strong>pub facts</strong>â€”stuff Iâ€™d ask my partner at a pub. â€œWhoâ€™s that guy who was in that movie where he did that thing?â€ They are incredible at this. Finding that one Reddit thread, that one article, or that one book. ChatGPT was able to <a href="https://chatgpt.com/share/68f03bcb-ba24-8013-9fa9-f14b2c79ae6f">find an article I saw on Hacker News</a>, despite me telling it an incorrect date, and it <a href="https://chatgpt.com/share/68f03bfe-ad40-8013-ade6-87e7cfccd00c">one-shotted a book</a> that I could not find after several manual searches. (Notably, Claude was <a href="https://claude.ai/share/779988a5-8950-4182-abf4-1f7dfd9596c1">unable to find the same article</a>. Unsure why).</p>
<figure class="image_figure"><p><img src="/_astro/trust-one-shot.BN9zCZbU_1isU60.webp" alt="ChatGPT: 'Do you mean Trust[...]?'" width="1356" height="488" loading="lazy" decoding="async">
<figcaption>ChatGPT finds a book</figcaption></p></figure>
<p>I also enjoy using LLMs to <strong>explain well-known concepts</strong>. Iâ€™ll ask them things an industry expert would instantly know. Iâ€™ve used them to help me <a href="https://chatgpt.com/share/68fed6b3-bca0-8013-9996-067816baee88">use command-line tools</a> I donâ€™t frequently use, guess at syntax <a href="https://chatgpt.com/share/68fee21c-0918-8013-b880-8b5c11be3283">when writing a plugin</a> and <a href="https://chatgpt.com/share/68fee290-e10c-8013-811b-8345d1ca1cb8">when using an unfamiliar markup language</a>, and even <a href="https://chatgpt.com/share/68fee271-a098-8013-a374-ab2babfbbeef">find the right airport terminal</a> for a flight. Itâ€™sâ€¦ kinda nice to search <a href="https://www.google.com/search?q=superman+after+credits+scene">â€œsuperman after credits sceneâ€</a> and actually get an answer in the <a href="https://search.google/ways-to-search/ai-overviews/">AI overview</a> at the top.</p>
<p>However, I donâ€™t trust LLM answers much. ChatGPT confidently claimed a Switch 2 could use Switch 1 docks (<a href="https://en-americas-support.nintendo.com/app/answers/detail/a_id/68426/~/compatibility-of-nintendo-switch-with-nintendo-switch%26nbsp%3B2#s1q2">it cannot</a>). It was <a href="https://chatgpt.com/share/68fee9c8-1cf8-8013-9b28-d26c53adc8bd">simply incorrect about an obscure .NET API</a>. And I donâ€™t have to write much about how Googleâ€™s overviews <a href="https://mashable.com/article/google-ai-search-memes-mistakes">are</a> <a href="https://mashable.com/article/google-ai-overviews-2025-review">very</a> <a href="https://www.ktvq.com/news/local-news/billings-police-dont-trust-google-ai-for-local-emergency-phone-numbers">frequently</a> <a href="https://bsky.app/profile/gregjenner.bsky.social/post/3lnhxkdywzc2m">wrong</a>. Iâ€™m not as gloomy as many, but itâ€™s clear that these machines are not human experts. <a href="https://devblogs.microsoft.com/oldnewthing/author/oldnewthing">Raymond Chen</a> is an expert, and his <a href="https://stackoverflow.com/questions/61601132/what-is-the-use-of-a-process-with-no-threads-in-windows#comment108965999_61601132">2-sentence comment</a> on an old StackOverflow question of mine is better than the, uh, <a href="https://chatgpt.com/share/68f040d8-9a60-8013-8bc2-ef3676b9a0a2">mediocre answers</a> that <a href="https://chatgpt.com/share/68f040fa-6d18-8013-9bef-531ea72509e8">LLMs give</a>. Theyâ€™ve had plenty of time to index his answer.</p>
<figure class="image_figure"><p><img src="/_astro/switch-compat.DhiwUrUW_Z2mbjeY.webp" alt="ChatGPT claims 'the Switch 1 dock should work perfectly fine with the Switch 2.'" width="1370" height="704" loading="lazy" decoding="async">
<figcaption>ChatGPT is wrong about Nintendo Switch docks</figcaption></p></figure>
<p>My trepidation extends to complex <strong>literature searches</strong>. I use LLMs as secondary librarians when Iâ€™m doing research. They reliably find primary sources (articles, papers, etc.) that I miss in my initial searches.</p>
<p>But these searches are <em>dangerous</em>. I distrust LLM librarians. There is so much data in the world: you can (in good faith!) find evidence to support almost any position or conclusion. ChatGPT is not a human, and, unlike teachers &amp; librarians &amp; scholars, ChatGPT does not have a consistent, legible worldview. In my experience, it readily agrees with any premise you hand itâ€Šâ€”â€Šand brings citations. It may have read every article that can be read, but it has no real opinionâ€Šâ€”â€Šso it is not a credible expert.</p>
<figure class="image_figure"><p><img src="/_astro/latency-detection.-ap5jazP_Z102OI7.webp" alt="ChatGPT chat: How fast is human latency detection in interaction loops" width="1368" height="626" loading="lazy" decoding="async"></p><figcaption><p>ChatGPT does not have a worldview: how much of <a href="https://chatgpt.com/share/6906475e-8ee0-8013-b56b-311b4d669408">this answer</a> is right? How much is sycophancy?</p></figcaption></figure>
<p>For example, ChatGPT was able to find lots of citations regarding <a href="https://chatgpt.com/share/6906475e-8ee0-8013-b56b-311b4d669408">human latency thresholds</a> and <a href="https://chatgpt.com/share/68f041e0-2070-8013-b6d8-511c77bff30d">some keyboarding topics Iâ€™m researching</a>. But many of its quotes were out-of-date (or hallucinations)! In this case, <em>I</em> am the expert, wondering if there are additional sources worth citing; I can audit AI output. But AI has <a href="https://arstechnica.com/tech-policy/2025/05/judge-initially-fooled-by-fake-ai-citations-nearly-put-them-in-a-ruling/#:~:text=%20It%20almost%20led%20to%20the%20scarier%20outcome%20(from%20my%20perspective)%20of%20including%20those%20bogus%20materials%20in%20a%20judicial%20order.">almost fooled</a> expert judges and lawyers already! Woe to any perplexed student seeking guidance.</p>



































<table><thead><tr><th style="text-align:right"></th><th style="text-align:center">Usefulness</th><th>Notes</th></tr></thead><tbody><tr><td style="text-align:right"><strong>Traditional search</strong></td><td style="text-align:center">âŒ</td><td>Worse than just using Google</td></tr><tr><td style="text-align:right"><strong>Product search</strong></td><td style="text-align:center">âŒ</td><td>Poisoned by the Internet</td></tr><tr><td style="text-align:right"><strong>Pub facts</strong></td><td style="text-align:center">ğŸ‘ğŸ‘</td><td>Makes me more annoying at parties!</td></tr><tr><td style="text-align:right"><strong>Explaining well-known concepts</strong></td><td style="text-align:center">ğŸ‘</td><td>Sometimes better than the docs. Mostly correct.</td></tr><tr><td style="text-align:right"><strong>Literature searches</strong></td><td style="text-align:center">âš ï¸ğŸ‘</td><td>ChatGPT finds evidence to support any claim, and thatâ€™s scary</td></tr></tbody></table>
<h2 id="summarization--transcription">Summarization &amp; transcription</h2>
<p>Perhaps itâ€™s odd to emphasize <strong>summarization</strong> and <strong>transcription</strong>, but LLMs are <em>so dang good at it</em>.</p>
<p>LLMs care not about tedium. Theyâ€™ll read hundreds of pages &amp; spit out a perfect summary in less than a minute. For example, Microsoft Teams can automatically summarize meetings, and its summaries are incredible. Itâ€™s humbling to see an hour of discussion reduced to 5 bullet points.</p>
<p>Iâ€™ve heard concerns that LLMs <a href="https://arxiv.org/abs/2307.03172">are inattentive to stuff in the middle of long documents</a>, but I havenâ€™t experimented enough to notice firsthand. I do know that LLMs need <em>lots</em> of prompting to produce short-enough, clear summaries. They otherwise tend to ramble.</p>




















<table><thead><tr><th style="text-align:right"></th><th style="text-align:center">Usefulness</th><th>Notes</th></tr></thead><tbody><tr><td style="text-align:right"><strong>Summarization</strong></td><td style="text-align:center">ğŸ‘ğŸ‘</td><td>So good that itâ€™s no longer magical, but not super necessary day-to-day</td></tr><tr><td style="text-align:right"><strong>Transcription</strong></td><td style="text-align:center">ğŸ‘ğŸ‘</td><td>Ditto</td></tr></tbody></table>
<h2 id="writing">Writing</h2>
<p>I do not use AI to <strong>write from scratch</strong>. Nor do I use it as an outlining aid.</p>
<p>Thatâ€™s partly selfishness: clear communication is a rare skill among software engineers. Why cede an opportunity to practice?</p>
<p>But itâ€™s also practicality: every document relies on context that LLMs have no access to (because itâ€™s in emails or from a meeting or on paper or in your brain). So a generated document is guaranteed to be hallucinated pablum. Why would I want to hallucinate a dev specâ€Šâ€”â€Šthe document I use to get feedback on &amp; plan months of work?</p>
<p>At work, my goal is to communicate <em>my</em> most important ideas. Not AIâ€™s. I want my words to be purposeful &amp; apt. I want to build lovely things. That is not served by filling my colleaguesâ€™ inboxes with vomit.</p>

<figure class="image_figure"><picture> <source srcset="/_astro/vomit-dark.xhlY2zul_Z1VBSGe.webp 500w, /_astro/vomit-dark.xhlY2zul_Z1x3a2C.webp 700w, /_astro/vomit-dark.xhlY2zul_Z1EozKu.webp 1400w" type="image/webp">  <img src="/_astro/vomit-dark.xhlY2zul_Z11n2g5.png" srcset="/_astro/vomit-dark.xhlY2zul_Z11n2g5.png 500w, /_astro/vomit-dark.xhlY2zul_ZBNiBt.png 700w, /_astro/vomit-dark.xhlY2zul_1u9kqp.png 1400w" alt="A perplexed person attempts to read a ream of documents provided by a business-like robot" width="500" height="286" loading="lazy" decoding="async" class="key_image light-hidden"> </picture> <picture> <source srcset="/_astro/vomit.CFeZeYMp_jI0Xp.webp 500w, /_astro/vomit.CFeZeYMp_1Nxji5.webp 700w, /_astro/vomit.CFeZeYMp_mXMwp.webp 1400w" type="image/webp">  <img src="/_astro/vomit.CFeZeYMp_rqroy.png" srcset="/_astro/vomit.CFeZeYMp_rqroy.png 500w, /_astro/vomit.CFeZeYMp_1VfJIe.png 700w, /_astro/vomit.CFeZeYMp_ZM8TYW.png 1400w" alt="A perplexed person attempts to read a ream of documents provided by a business-like robot" width="500" height="286" loading="lazy" decoding="async" class="key_image dark-hidden"> </picture><figcaption>That is not served by filling my colleaguesâ€™ inboxes with vomit</figcaption></figure>
<p>Likewise, this blog is art to me. I am a <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/#:~:text=you%20live%20an%20idyllic%20life%20lounging%20about%2C%20eating%2C%20and%20composing%20great%20works%20of%20art">happy little rat of NIMH, making my art</a>, and I have no desire to cede that art to a machine. Iâ€™m fine using them to help me <strong>find good words</strong> (e.g. <a href="https://chatgpt.com/share/6902d18b-036c-8013-bdb4-09a6a50c7fdc">finding a word</a> for <a href="https://ben.stolovitz.com/posts/tiktok_will_always_be_temporary#:~:text=stuff%20hardens%2C-,calcifies,-.%20One%20day%2C%20it">TikTok will always be temporary</a>), but I believe I communicate effectively &amp; clearly. I have my friends edit: that is a joyous process (my editors enjoy it, right?). Interfacing with a machine is not.</p>
<p>So I donâ€™t ask the machines to write for me.</p>
<p>AI is an <em>uncanny</em> <strong>editor</strong> though. I recently asked both Claude and ChatGPT for feedback on some formal documents I was writing, and they were great! These documents had multiple pages of guidelines; I pasted my draft, I pasted the guidelines, and I asked for suggestions. The LLMs identified critical gaps in my responses &amp; punched up the prose.</p>
<p>Itâ€™s scary how good they can be. Iâ€™ve taken to <em>avoiding AIâ€™s verbatim suggestions</em> and rewriting on my ownâ€Šâ€”â€Šit often rephrases things <em>so well</em> that I worry it will usurp my voice. So I donâ€™t edit with AI on this blog or in my personal writing, although I wonder if my opinion here will ever change.</p>
<p>Luckily, LLMs still need good grounding to write well. Without clear human ideas, their writing is verbose and insipid. And Iâ€™ve seen Claude miss rhetorical patterns that would have been obvious to a human reader. But when I have a good idea, these machines can make it <em>so</em> much better. Itâ€™s terrifying.</p>

























<table><thead><tr><th style="text-align:right"></th><th style="text-align:center">Usefulness</th><th>Notes</th></tr></thead><tbody><tr><td style="text-align:right"><strong>Writing from scratch</strong></td><td style="text-align:center">âŒ</td><td>Ew. Why?</td></tr><tr><td style="text-align:right"><strong>Finding good words</strong></td><td style="text-align:center">ğŸ‘ğŸ‘</td><td>Good, clean fun</td></tr><tr><td style="text-align:right"><strong>Editing</strong></td><td style="text-align:center">âš ï¸ğŸ‘ğŸ‘ğŸ‘</td><td>Scary good.</td></tr></tbody></table>
<h2 id="art--music">Art &amp; music</h2>
<p>Lastly, art. I have not found a great use for <strong>image generation</strong>. I used Bing to generate playlist art for my Spotify playlists &amp; a few email memes, but Iâ€™ve stopped. I donâ€™t find it valuable. Plus, I dislike any AI art I notice. Cover photos on blogs, bad comics on social media, ew. It <em>is</em> useful, but in a stupid way: itâ€™s a signal that accompanying text will also be AI-generated.</p>
<figure class="image_figure"><p><img src="/_astro/spotify.CQcebfdZ_Z2hGmbU.webp" alt="My Bing-generated art on my Spotify playlist" width="1368" height="474" loading="lazy" decoding="async">
<figcaption>My AI playlist art</figcaption></p></figure>
<p>Iâ€™m certain of this distaste now that Iâ€™ve started seeing AI art in the physical world. Thereâ€™s a clothing store near me with an AI-generated mural, and I believe I saw AI-designed merchandise at a museum gift shop. Gross! Itâ€™s off-putting to see those humanless pictures in real life.</p>
<p>Why would I add to the slop?</p>
<p>I think <strong>music generation</strong> is headed down the same path. I donâ€™t generate or plan to generate any music with AI myself, but Iâ€™ve already heard several <em>lovely</em> AI-generated songs this year. One in particularâ€Šâ€”â€Ša song about <a href="https://www.instagram.com/p/DPFMae9Eq-y/">transporting steel coils</a> (&quot;Iâ€™ve been curious/â€‹why steel coils are transported on their side/â€‹instead of flatâ€¦&quot;)â€”inspired me to start writing my own music again. But I think Iâ€™ll get tired of it quickly.</p>
<aside class="sidenote"><h3 id="when-will-i-get-bored-of-ai-music">When will I get bored of AI music?</h3><p>When image generation first came out, it was wonky enough to be charming, and it was hard to use. The wonk meant that generating viral images required fair amounts of human guidance &amp; creativity, and the difficulty meant users were generally enthusiastsâ€Šâ€”â€Šso I saw more delightful stuff. Music generation seems to be in a similar state. The steel coils song is viral <em>in spite of</em> its rhymeless, rhythmically-challenged structure and bizarre, noisy instrumentation: itâ€™s <em>fun</em>. (Plus, weâ€™re already used to Hatsune Miku and Auto-Tune). Suno already generates <a href="https://suno.com/s/rjbeVGss0LjDk1Bt">good</a>, real-sounding <a href="https://suno.com/s/aKUTQVdGc2HFKit0">music</a>.</p><p>As we get inundated with ersatz Dierks Bentley and Nickleback, AI music will become as irritating as image generation is now.</p></aside>
<p>Perhaps the best that can be said of AI art is that it lowers the bar to create. At its best, it empowers us to invent beyond artâ€™s typical cliches. Producing a song takes hundreds of hoursâ€Šâ€”â€Šso if you asked me to record a rhymeless, tuneless song about steel coil transportation (or a perhaps-copyright-infringey <a href="https://www.youtube.com/watch?v=MXZrp_NaozI">song about Warhammer characters</a>) Iâ€™d laugh at you. Iâ€™d be wrong.</p>
<figure class="image_figure"><p><img src="/_astro/steel-coils.Dpw94cJe_ApIuX.webp" alt="learningwithlyrics' Instagram steel coils post" width="2052" height="992" loading="lazy" decoding="async"></p><figcaption><p>The <a href="https://www.instagram.com/p/DPFMae9Eq-y/">steel coils song</a> is silly and nonsensicalâ€¦ and delightful</p></figcaption></figure>
<p>But in practice, I think AI art gets suborned for laziness, stinginess, and grift. It is a shame that these songs are not voiced by human session singers, laughing at the lyrics in their recording booths. Art should increase human connection, not obsolete it. I do not want to use a faux-Ghibli portrait as my profile picture. And if you ask me: would I like AI to generate some art today?</p>
<p>Iâ€™d rather doodle.</p>




















<table><thead><tr><th style="text-align:right"></th><th style="text-align:center">Usefulness</th><th>Notes</th></tr></thead><tbody><tr><td style="text-align:right"><strong>Image generation</strong></td><td style="text-align:center">âŒ</td><td>Unpleasant when I detect it. Less fun than drawing a stick figure.</td></tr><tr><td style="text-align:right"><strong>Music generation</strong></td><td style="text-align:center">ğŸ¤”</td><td>I bet Iâ€™ll dislike it soon</td></tr></tbody></table>
<h2 id="conclusion-and-boring-ai">Conclusion (and â€œboringâ€ AI)</h2>
<p>Overall, this new wave of AI has transformed how I work. Autocompletion for my coding &amp; human-like chat for random tip-of-my-tongue questionsâ€Šâ€”â€Šawesome.</p>
<p>Iâ€™m confident weâ€™re just starting to see what AI can achieve. Even if models stay the same, I <em>know</em> we havenâ€™t fully explored what they can do. LLMs are still in their â€œwondrousâ€ phase; compare that to all the AI we take for granted. Good search, good recommendations, spellcheck, autocomplete. I simply expect to talk to my phone while I drive, and I rely on Siri to schedule my reminders.</p>
<p>The new AI will become normal, too. It will become pedestrian. Thereâ€™s lots of good in what we have now, lots of mediocre, lots of bad, lots of <em>scary</em>. I hope itâ€™s useful to document what this feels like, when itâ€™s all new.</p>
<p>When itâ€™s normal, I hope itâ€™s mostly good.</p>
<hr/>
<p><em>Thanks to Atherai Maran for editing.</em></p> </article> <hr data-astro-cid-egg7nqdx> <aside data-astro-cid-egg7nqdx> <nav class="bottom_nav" data-astro-cid-egg7nqdx> <a class="prev" href="/posts/accessible_design_is_design/" data-astro-cid-egg7nqdx>&larr; Accessible design is design</a>  </nav> <span class="print-only" data-astro-cid-egg7nqdx> <a href="https://ben.stolovitz.com/" data-astro-cid-egg7nqdx>ben.stolovitz.com</a> //
</span> 
Published
<time datetime="2025-10-31T00:00:00.000Z" data-astro-cid-egg7nqdx> Oct 31, 2025 </time>  
// Last modified
<time datetime="2025-11-01T20:51:55.000Z" title="November 1, 2025 4:51 PM" data-astro-cid-egg7nqdx> Nov 1, 2025 </time>  </aside> <section class="email" data-astro-cid-3jjkyeai> <h2 id="email-title" data-astro-cid-3jjkyeai>Want to see new stuff?</h2> <form aria-labelledby="email-title" action="https://buttondown.com/api/emails/embed-subscribe/citelao" method="post" target="popupwindow" onsubmit="window.open('https://buttondown.com/citelao', 'popupwindow')" class="embeddable-buttondown-form" data-astro-cid-3jjkyeai> <input type="hidden" value="1" name="embed" data-astro-cid-3jjkyeai> <input type="hidden" name="tag" value="via-homepage" data-astro-cid-3jjkyeai> <input type="email" name="email" placeholder="cool_person@aol.net" aria-label="Email" aria-describedby="email-description" required data-astro-cid-3jjkyeai> <input type="submit" value="Subscribe" data-astro-cid-3jjkyeai> </form> <small id="email-description" data-astro-cid-3jjkyeai>
No spam. Just an email for new posts.
</small> </section> </main>   <menu data-astro-cid-egg7nqdx> <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).only=e;window.dispatchEvent(new Event("astro:only"));})();;(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="fFwL3" component-url="/_astro/ThemeButton.DLzJdG7X.js" component-export="default" renderer-url="/_astro/client.CSdlLnY0.js" props="{&quot;data-astro-cid-egg7nqdx&quot;:[0,true]}" ssr client="only" opts="{&quot;name&quot;:&quot;ThemeToggle&quot;,&quot;value&quot;:true}"></astro-island> </menu>  </body></html>